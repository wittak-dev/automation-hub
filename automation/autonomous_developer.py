"""Autonomous Developer - Phase 2.2: Backlog-Driven (Auto Issue Creation)"""

import os
import subprocess
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
from github import Github
from anthropic import Anthropic
import json
import re

class AutonomousDeveloper:
    def __init__
    def _apply_modification_smart(self, repo_path: Path, change: dict) -> bool:
        """
        Intelligently apply modifications based on file type.
        For config files (JSON/TS configs), merge changes instead of replacing entire file.
        """
        file_path = repo_path / change['file']
        content = change['content']
        
        # Check if this is a config file that should be merged
        config_files = ['package.json', 'tsconfig.json', 'vite.config.ts', 'vitest.config.ts']
        is_config = any(file_path.name == cf for cf in config_files)
        
        if is_config and file_path.name.endswith('.json'):
            # JSON config file - merge intelligently
            try:
                import json
                
                # Read existing file
                if not file_path.exists():
                    # If file doesn't exist, treat as create
                    file_path.write_text(content)
                    return True
                
                existing_content = json.loads(file_path.read_text())
                
                # Parse the partial changes Claude provided
                try:
                    changes = json.loads(content) if isinstance(content, str) else content
                except json.JSONDecodeError:
                    # Claude might have provided invalid JSON snippet
                    # Fall back to full replacement
                    print(f"   ‚ö†Ô∏è  Could not parse JSON changes for {file_path.name}, using full replacement")
                    file_path.write_text(content)
                    return True
                
                # Deep merge the changes
                def deep_merge(base, updates):
                    """Recursively merge updates into base"""
                    for key, value in updates.items():
                        if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                            deep_merge(base[key], value)
                        else:
                            base[key] = value
                    return base
                
                merged = deep_merge(existing_content.copy(), changes)
                
                # Write back with proper formatting
                file_path.write_text(json.dumps(merged, indent=2) + '
')
                print(f"   ‚úÖ Merged changes into {file_path.name}")
                return True
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Merge failed for {file_path.name}: {e}")
                print(f"   üìù Falling back to full file replacement")
                file_path.write_text(content)
                return True
        
        elif is_config and file_path.name.endswith('.ts'):
            # TypeScript config - for now, do full replacement
            # TODO: Could implement smart merging for TS configs too
            file_path.write_text(content)
            return True
        
        else:
            # Regular code file - full replacement
            file_path.write_text(content)
            return True

    def __init__(self, github_token: str, anthropic_api_key: str):
        self.github = Github(github_token)
        self.anthropic = Anthropic(api_key=anthropic_api_key)
        self.username = os.getenv('GITHUB_USERNAME', 'wittak-dev')
        self.workspace = Path.home() / 'automation-hub' / 'workspace'
        self.workspace.mkdir(exist_ok=True)
        print("‚úÖ AutonomousDeveloper initialized (Phase 2.2: Backlog-Driven)")
    
    async def run_development_cycle(self, project: str) -> Dict:
        """Full autonomous development cycle with backlog-driven issue creation"""
        print(f"üî® Starting backlog-driven autonomous development for {project}...")
        
        try:
            repo_name = 'WhatsAppAnalyser_v2' if project == 'whatsapp' else 'HealthOS-v2_Replit'
            repo = self.github.get_user(self.username).get_repo(repo_name)
            
            # Step 1: Quick shallow clone to read planning documents
            print(f"üì¶ Quick clone to read roadmap/backlog...")
            temp_clone = self._quick_clone(repo_name)
            
            # Step 2: Load strategic priorities
            priorities = self._load_project_priorities(temp_clone, project)
            
            # Step 3: Get open issues
            issues = list(repo.get_issues(state='open'))
            
            # NEW: Step 3b - If no issues, create from backlog
            if not issues:
                print(f"üìù No open issues found - creating from backlog...")
                created_issue = await self._create_issue_from_backlog(
                    repo=repo,
                    repo_path=temp_clone,
                    project=project,
                    priorities=priorities
                )
                
                if created_issue:
                    print(f"‚úÖ Created Issue #{created_issue.number}: {created_issue.title}")
                    issues = [created_issue]
                else:
                    shutil.rmtree(temp_clone)
                    return {
                        "status": "no_work",
                        "message": "No backlog items suitable for autonomous work",
                        "tasks_completed": 0
                    }
            
            # Step 4: Select best issue based on priorities
            selected_issue = await self._select_priority_issue(
                issues=issues,
                project=project,
                priorities=priorities
            )
            
            # Cleanup temp clone
            shutil.rmtree(temp_clone)
            
            if not selected_issue:
                return {
                    "status": "no_suitable_issue",
                    "message": "No issues suitable for autonomous development",
                    "tasks_completed": 0
                }
            
            print(f"üìã Selected Issue #{selected_issue.number}: {selected_issue.title}")
            print(f"   üéØ Aligns with roadmap priorities")
            
            # Step 5: Full clone for development
            repo_path = self._prepare_workspace(project, repo_name, selected_issue)
            
            # Step 6: Load constitutional framework
            constitution = self._load_constitution(repo_path, project)
            
            # Step 7: Generate solution
            solution = await self._generate_solution(
                issue=selected_issue,
                constitution=constitution,
                repo_path=repo_path,
                project=project,
                priorities=priorities
            )
            
            if solution['status'] != 'success':
                shutil.rmtree(repo_path)
                return {
                    "status": "generation_failed",
                    "error": solution.get('error'),
                    "tasks_completed": 0
                }
            
            # Step 8: Apply changes
            changes_applied = self._apply_changes(repo_path, solution['changes'])
            
            if not changes_applied:
                shutil.rmtree(repo_path)
                return {
                    "status": "changes_failed",
                    "tasks_completed": 0
                }
            
            # Step 9: Run tests
            test_results = self._run_tests(repo_path, project)
            
            if not test_results['passed']:
                print(f"‚ö†Ô∏è  Tests failed, skipping PR creation")
                shutil.rmtree(repo_path)
                return {
                    "status": "tests_failed",
                    "test_output": test_results['output'][:500],
                    "tasks_completed": 0
                }
            
            # Step 10: Format code
            self._format_code(repo_path, project)
            
            # Step 11: Commit and push
            branch_name = f"autonomous/issue-{selected_issue.number}"
            self._commit_and_push(repo_path, branch_name, selected_issue)
            
            # Step 12: Create PR
            pr = self._create_pull_request(
                repo=repo,
                branch=branch_name,
                issue=selected_issue,
                solution=solution
            )
            
            # Step 13: Update project docs
            self._update_project_docs(repo_path, selected_issue, pr, project)
            
            # Cleanup
            shutil.rmtree(repo_path)
            
            return {
                "status": "pr_created",
                "pr_url": pr.html_url,
                "issue_number": selected_issue.number,
                "issue_title": selected_issue.title,
                "tasks_completed": 1,
                "branch": branch_name
            }
            
        except Exception as e:
            print(f"‚ùå Error in development cycle: {e}")
            import traceback
            traceback.print_exc()
            return {
                "status": "error",
                "error": str(e),
                "tasks_completed": 0
            }
    
    # =========================================================================
    # NEW: BACKLOG-DRIVEN ISSUE CREATION
    # =========================================================================
    
    async def _create_issue_from_backlog(
        self,
        repo,
        repo_path: Path,
        project: str,
        priorities: str
    ) -> Optional:
        """Extract a work item from BACKLOG.md and create a GitHub issue"""
        
        # Load the full backlog
        backlog_content = self._load_full_backlog(repo_path, project)
        
        if not backlog_content:
            print("   ‚ö†Ô∏è  No backlog content found")
            return None
        
        # Ask Claude to extract the best autonomous-ready task
        prompt = f"""Analyse this project backlog and extract ONE task suitable for autonomous 3AM development.

PROJECT: {project}

BACKLOG/ROADMAP CONTENT:
{backlog_content[:8000]}

REQUIREMENTS FOR SELECTION:
1. Task must be CONCRETE and IMPLEMENTABLE (not vague like "improve performance")
2. Task should be achievable in 1-2 hours of focused work
3. Task should NOT require:
   - External API keys or credentials
   - User input or manual testing
   - Database migrations
   - Breaking changes to public APIs
4. PREFER tasks that are:
   - Bug fixes with clear reproduction steps
   - Adding tests for existing functionality
   - Documentation improvements
   - Small feature additions with clear specs
   - Refactoring with clear scope
   - Accessibility improvements
   - UI polish items

OUTPUT FORMAT (JSON):
{{
    "title": "Clear, concise issue title",
    "body": "Detailed description including:\\n- What needs to be done\\n- Acceptance criteria\\n- Files likely to be affected",
    "labels": ["autonomous-created", "3am-ready", "<other-relevant-labels>"],
    "backlog_reference": "Which section/item this came from",
    "confidence": "high/medium/low",
    "estimated_complexity": "simple/moderate/complex"
}}

If NO suitable task exists, respond with:
{{"status": "no_suitable_task", "reason": "explanation"}}

Respond with ONLY valid JSON."""

        try:
            message = self.anthropic.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=1500,
                messages=[{"role": "user", "content": prompt}]
            )
            
            response_text = message.content[0].text.strip()
            
            # Parse JSON response
            # Handle potential markdown code blocks
            if response_text.startswith("```"):
                response_text = re.sub(r'^```(?:json)?\n?', '', response_text)
                response_text = re.sub(r'\n?```$', '', response_text)
            
            task_data = json.loads(response_text)
            
            # Check if no suitable task
            if task_data.get('status') == 'no_suitable_task':
                print(f"   ‚ÑπÔ∏è  No suitable task: {task_data.get('reason', 'unknown')}")
                return None
            
            # Validate we have required fields
            if not task_data.get('title') or not task_data.get('body'):
                print("   ‚ö†Ô∏è  Invalid task data from Claude")
                return None
            
            # Skip if low confidence or complex
            if task_data.get('confidence') == 'low':
                print("   ‚ö†Ô∏è  Low confidence task - skipping")
                return None
            
            if task_data.get('estimated_complexity') == 'complex':
                print("   ‚ö†Ô∏è  Complex task - skipping for autonomous work")
                return None
            
            # Create the GitHub issue
            print(f"   üìù Creating issue: {task_data['title']}")
            
            # Build issue body with metadata
            issue_body = f"""{task_data['body']}

---
ü§ñ *This issue was automatically created by the Autonomous Developer from the project backlog.*

**Source**: {task_data.get('backlog_reference', 'BACKLOG.md')}
**Confidence**: {task_data.get('confidence', 'medium')}
**Complexity**: {task_data.get('estimated_complexity', 'moderate')}
**Created**: {datetime.now().strftime('%Y-%m-%d %H:%M')}
"""
            
            # Ensure labels exist (create if needed)
            labels = task_data.get('labels', ['autonomous-created', '3am-ready'])
            valid_labels = self._ensure_labels_exist(repo, labels)
            
            # Create the issue
            issue = repo.create_issue(
                title=task_data['title'],
                body=issue_body,
                labels=valid_labels
            )
            
            print(f"   ‚úÖ Issue #{issue.number} created successfully")
            return issue
            
        except json.JSONDecodeError as e:
            print(f"   ‚ö†Ô∏è  Failed to parse Claude response: {e}")
            return None
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Failed to create issue: {e}")
            return None
    
    def _load_full_backlog(self, repo_path: Path, project: str) -> str:
        """Load complete backlog content for issue extraction"""
        
        backlog_parts = []
        
        if project == 'whatsapp':
            files_to_load = [
                ('BACKLOG.md', repo_path / 'BACKLOG.md'),
                ('ACCEPTANCE_CRITERIA_STATUS.md', repo_path / 'ACCEPTANCE_CRITERIA_STATUS.md'),
            ]
            
            # Also check roadmap directory
            roadmap_dir = repo_path / 'docs' / 'roadmap'
            if roadmap_dir.exists():
                # Get current release spec (most relevant)
                for spec in sorted(roadmap_dir.glob('v*.md'), reverse=True)[:1]:
                    files_to_load.append((f'Current Release: {spec.name}', spec))
        else:
            files_to_load = [
                ('BACKLOG.md', repo_path / 'BACKLOG.md'),
                ('COMPREHENSIVE_TECHNICAL_BACKLOG.md', repo_path / 'COMPREHENSIVE_TECHNICAL_BACKLOG.md'),
                ('BUGS_AND_ISSUES.md', repo_path / 'docs' / 'BUGS_AND_ISSUES.md'),
            ]
        
        for name, path in files_to_load:
            if path.exists():
                try:
                    content = path.read_text()
                    backlog_parts.append(f"=== {name} ===\n{content}\n")
                    print(f"   ‚úÖ Loaded {name} ({len(content)} chars)")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è  Could not load {name}: {e}")
        
        return "\n\n".join(backlog_parts)
    
    def _ensure_labels_exist(self, repo, labels: List[str]) -> List[str]:
        """Ensure labels exist in repo, create if needed"""
        existing_labels = {label.name.lower(): label.name for label in repo.get_labels()}
        valid_labels = []
        
        label_colors = {
            'autonomous-created': '7057ff',  # Purple
            '3am-ready': '0e8a16',           # Green
            'backlog': 'fbca04',             # Yellow
            'quick-win': 'c5def5',           # Light blue
            'bug': 'd73a4a',                 # Red
            'enhancement': 'a2eeef',         # Cyan
            'documentation': '0075ca',       # Blue
        }
        
        for label in labels:
            label_lower = label.lower()
            
            if label_lower in existing_labels:
                valid_labels.append(existing_labels[label_lower])
            else:
                # Create the label
                try:
                    color = label_colors.get(label_lower, 'ededed')
                    repo.create_label(name=label, color=color)
                    valid_labels.append(label)
                    print(f"   üè∑Ô∏è  Created label: {label}")
                except Exception as e:
                    # Label might already exist with different case
                    print(f"   ‚ö†Ô∏è  Could not create label {label}: {e}")
        
        return valid_labels
    
    # =========================================================================
    # EXISTING METHODS (unchanged from Phase 2.1)
    # =========================================================================
    
    def _quick_clone(self, repo_name: str) -> Path:
        """Smart clone with caching for reading strategic docs"""
        
        # Use persistent cache directory
        cache_dir = Path.home() / '.automation-cache' / 'repos'
        cache_dir.mkdir(parents=True, exist_ok=True)
        
        repo_path = cache_dir / repo_name
        repo_url = self._get_repo_url(repo_name)
        
        # If cached, just update it
        if repo_path.exists() and (repo_path / '.git').exists():
            try:
                print(f"üì¶ Updating cached {repo_name}...")
                subprocess.run(
                    ['git', 'fetch', 'origin', 'main'],
                    cwd=repo_path,
                    capture_output=True,
                    timeout=60,
                    check=True
                )
                subprocess.run(
                    ['git', 'reset', '--hard', 'origin/main'],
                    cwd=repo_path,
                    capture_output=True,
                    timeout=30,
                    check=True
                )
                print(f"‚úÖ Cache updated")
                return repo_path
            except Exception as e:
                print(f"‚ö†Ô∏è  Update failed, using cached version: {e}")
                return repo_path
        
        # First time: Clone with sparse checkout
        print(f"üì• First-time clone of {repo_name} (using sparse checkout)...")
        try:
            # Initialize
            repo_path.mkdir(parents=True, exist_ok=True)
            subprocess.run(['git', 'init'], cwd=repo_path, timeout=10, check=True)
            
            # Configure sparse checkout
            subprocess.run(
                ['git', 'config', 'core.sparseCheckout', 'true'],
                cwd=repo_path,
                timeout=10,
                check=True
            )
            
            # Define what to include
            sparse_patterns = self._get_sparse_patterns(repo_name)
            sparse_file = repo_path / '.git' / 'info' / 'sparse-checkout'
            sparse_file.parent.mkdir(parents=True, exist_ok=True)
            sparse_file.write_text('\n'.join(sparse_patterns))
            
            # Add remote and fetch
            subprocess.run(
                ['git', 'remote', 'add', 'origin', repo_url],
                cwd=repo_path,
                timeout=10,
                check=True
            )
            subprocess.run(
                ['git', 'fetch', '--depth', '1', 'origin', 'main'],
                cwd=repo_path,
                capture_output=True,
                timeout=120,
                check=True
            )
            subprocess.run(
                ['git', 'checkout', 'main'],
                cwd=repo_path,
                timeout=30,
                check=True
            )
            
            print(f"‚úÖ Sparse clone complete")
            return repo_path
            
        except subprocess.TimeoutExpired:
            print(f"‚ùå Clone timeout - repo may be too large")
            if repo_path.exists():
                shutil.rmtree(repo_path)
            raise
        except Exception as e:
            print(f"‚ùå Clone failed: {e}")
            if repo_path.exists():
                shutil.rmtree(repo_path)
            raise

    def _get_sparse_patterns(self, repo_name: str) -> list:
        """Define which files to clone (documentation only)"""
        if 'whatsapp' in repo_name.lower():
            return [
                'BACKLOG.md',
                'ACCEPTANCE_CRITERIA_STATUS.md',
                'docs/roadmap/*.md',
                'CLAUDE*.md',
                'README.md',
            ]
        else:  # HealthOS
            return [
                'BACKLOG.md',
                'SESSION_LOG.md',
                'COMPREHENSIVE_TECHNICAL_BACKLOG.md',
                'docs/*.md',
                'reports_plans_approaches/*.md',
                'CLAUDE*.md',
                'docs/GOVERNANCE*.md',
                'README.md',
            ]
    
    def _load_project_priorities(self, repo_path: Path, project: str) -> str:
        """Load BACKLOG.md, roadmap, and planning documents"""
        print(f"üìã Loading project priorities...")
        
        priorities = []
        
        # WhatsApp Analyser specific docs
        if project == 'whatsapp':
            planning_files = [
                ('BACKLOG.md', repo_path / 'BACKLOG.md'),
                ('Acceptance Criteria', repo_path / 'ACCEPTANCE_CRITERIA_STATUS.md'),
                ('Main Roadmap', repo_path / 'docs' / 'roadmap' / 'REVISED_Technical_Release_Sequence_Mobile_First_20251026.md'),
            ]
            
            # Check for release specs
            roadmap_dir = repo_path / 'docs' / 'roadmap'
            if roadmap_dir.exists():
                for spec_file in sorted(roadmap_dir.glob('v*.md'), reverse=True)[:2]:
                    planning_files.append((f'Release: {spec_file.name}', spec_file))
        
        # HealthOS specific docs  
        else:
            planning_files = [
                ('BACKLOG', repo_path / 'BACKLOG.md'),
                ('COMPREHENSIVE_TECHNICAL_BACKLOG', repo_path / 'COMPREHENSIVE_TECHNICAL_BACKLOG.md'),
                ('CURRENT_PRIORITIES', repo_path / 'docs' / 'CURRENT_PRIORITIES_20250922.md'),
                ('Project Plan', repo_path / 'reports_plans_approaches' / 'new_projectplan_20250907.md'),
            ]
        
        # Load each file
        for doc_name, doc_path in planning_files:
            if doc_path.exists():
                try:
                    content = doc_path.read_text()
                    # Take first 2000 chars to stay within token limits
                    priorities.append(f"## {doc_name}\n{content[:2000]}\n")
                    print(f"   ‚úÖ Loaded: {doc_name}")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è  Could not read {doc_name}: {e}")
        
        if priorities:
            result = "\n\n".join(priorities)
            print(f"   üìä Total context: {len(result)} chars from {len(priorities)} docs")
            return result
        else:
            print(f"   ‚ÑπÔ∏è  No planning documents found")
            return "No planning documents found - use best judgment"
    
    async def _select_priority_issue(
        self,
        issues: List,
        project: str,
        priorities: str
    ) -> Optional:
        """Select issue that aligns with roadmap priorities"""
        
        # Filter suitable issues
        suitable_issues = []
        for issue in issues[:15]:  # Check top 15
            labels = [label.name.lower() for label in issue.labels]
            
            # Skip blocked issues
            if any(x in labels for x in ['wontfix', 'invalid', 'duplicate', 'blocked']):
                continue
            
            # Prioritize well-labeled issues
            priority_score = 0
            if '3am-ready' in labels or 'autonomous-ready' in labels:
                priority_score += 100
            if 'autonomous-created' in labels:
                priority_score += 90  # High priority for our own created issues
            if 'roadmap' in labels or 'backlog' in labels:
                priority_score += 50
            if 'quick-win' in labels or 'good first issue' in labels:
                priority_score += 25
            if 'bug' in labels:
                priority_score += 10
            
            suitable_issues.append((priority_score, issue))
        
        if not suitable_issues:
            return None
        
        # Sort by priority
        suitable_issues.sort(reverse=True, key=lambda x: x[0])
        top_issues = [issue for score, issue in suitable_issues[:5]]
        
        # If we have an autonomous-created issue, prefer it
        for issue in top_issues:
            labels = [label.name.lower() for label in issue.labels]
            if 'autonomous-created' in labels:
                return issue
        
        # Ask Claude to select based on priorities
        issues_text = "\n\n".join([
            f"Issue #{issue.number}: {issue.title}\nLabels: {[l.name for l in issue.labels]}\n{(issue.body or '')[:400]}"
            for issue in top_issues
        ])
        
        prompt = f"""Select the BEST GitHub issue for autonomous development at 3 AM.

PROJECT: {project}

STRATEGIC PRIORITIES (from BACKLOG, roadmap):
{priorities[:4000]}

AVAILABLE ISSUES:
{issues_text}

Choose the issue that:
1. **Best aligns** with strategic priorities above
2. Has clear, implementable requirements
3. Reasonable scope for autonomous work
4. Won't require external dependencies

Respond with ONLY the issue number (e.g., "42")."""
        
        try:
            message = self.anthropic.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=50,
                messages=[{"role": "user", "content": prompt}]
            )
            
            response = message.content[0].text.strip()
            issue_num = int(re.search(r'\d+', response).group())
            
            for issue in top_issues:
                if issue.number == issue_num:
                    return issue
            
            # Fallback to highest scored
            return top_issues[0]
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Claude selection failed: {e}")
            return top_issues[0] if top_issues else None
    
    def _get_repo_url(self, repo_name: str) -> str:
        """Get authenticated repo URL"""
        token = os.environ.get('GITHUB_TOKEN')
        return f"https://{token}@github.com/{self.username}/{repo_name}.git"
    
    def _prepare_workspace(self, project: str, repo_name: str, issue) -> Path:
        """Prepare workspace for development"""
        print(f"üèóÔ∏è  Preparing workspace...")
        
        workspace = self.workspace / f"{project}_issue_{issue.number}"
        if workspace.exists():
            shutil.rmtree(workspace)
        
        # Full clone for development
        repo_url = self._get_repo_url(repo_name)
        subprocess.run(
            ['git', 'clone', '--depth', '50', repo_url, str(workspace)],
            capture_output=True,
            timeout=300,
            check=True
        )
        
        print(f"   ‚úÖ Workspace ready at {workspace}")
        return workspace
    
    def _load_constitution(self, repo_path: Path, project: str) -> str:
        """Load CLAUDE.md constitutional framework"""
        print(f"üìú Loading constitutional framework...")
        
        constitution_parts = []
        
        # Main CLAUDE.md
        main_claude = repo_path / 'CLAUDE.md'
        if main_claude.exists():
            constitution_parts.append(main_claude.read_text()[:5000])
            print(f"   ‚úÖ Loaded CLAUDE.md")
        
        # Supporting CLAUDE files
        for claude_file in repo_path.glob('CLAUDE_*.md'):
            try:
                constitution_parts.append(claude_file.read_text()[:2000])
                print(f"   ‚úÖ Loaded {claude_file.name}")
            except:
                pass
        
        if constitution_parts:
            return "\n\n---\n\n".join(constitution_parts)
        else:
            return "No constitutional framework found - follow best practices"
    
    async def _generate_solution(
        self,
        issue,
        constitution: str,
        repo_path: Path,
        project: str,
        priorities: str
    ) -> Dict:
        """Generate code solution using Claude"""
        print(f"üß† Generating solution...")
        
        # Get relevant file context
        file_context = self._get_file_context(repo_path, project, issue)
        
        prompt = f"""You are an autonomous developer working at 3 AM on the {project} project.

CONSTITUTIONAL FRAMEWORK (must follow):
{constitution[:3000]}

CURRENT STRATEGIC PRIORITIES:
{priorities[:2000]}

ISSUE TO SOLVE:
Title: {issue.title}
Body: {issue.body or 'No description'}
Labels: {[l.name for l in issue.labels]}

RELEVANT FILE CONTEXT:
{file_context[:4000]}

TASK:
Generate a complete solution for this issue. Your solution must:
1. Follow the constitutional framework strictly
2. Align with strategic priorities
3. Include ALL necessary file changes
4. Be production-ready (no TODOs, no placeholders)
5. Include appropriate tests if applicable

OUTPUT FORMAT (JSON):
{{
    "analysis": "Brief analysis of the issue and approach",
    "changes": [
        {{
            "file": "path/to/file.ext",
            "action": "create|modify|delete",
            "content": "CONTENT RULES - READ CAREFULLY:
                - For action='create': Full file content (required)
                - For action='modify' on CONFIG FILES (package.json, tsconfig.json, vite.config.ts, etc):
                  ONLY include the specific sections being added/changed as a JSON object/snippet
                  Example: {{\"scripts\": {{\"test\": \"vitest\", \"new-script\": \"command\"}}}}
                  DO NOT include the entire file - we will merge your changes into the existing file
                - For action='modify' on CODE FILES:
                  If file is small (<200 lines): Full file content is OK
                  If file is large (>200 lines): Use line-based changes:
                  {{\"line_changes\": [{{\"start\": 10, \"end\": 20, \"new_content\": \"...\"}}, ...]}}
                - For action='delete': Set content to empty string",
            "description": "what this change does"
        }}
    ],
    "tests_to_run": ["npm test", "pytest", etc],
    "commit_message": "type: description following conventional commits"
}}

CRITICAL: For modifications to package.json, vite.config.ts, tsconfig.json and similar config files,
return ONLY the specific keys/sections being added or modified. We will intelligently merge them.
This prevents token limit issues.

Respond with ONLY valid JSON."""

        try:
            message = self.anthropic.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=8000,
                messages=[{"role": "user", "content": prompt}]
            )
            
            response_text = message.content[0].text.strip()
            
            # Handle markdown code blocks
            if response_text.startswith("```"):
                response_text = re.sub(r'^```(?:json)?\n?', '', response_text)
                response_text = re.sub(r'\n?```$', '', response_text)
            
            # Save raw response for debugging
            debug_file = Path.home() / 'automation-hub' / 'logs' / f'claude_response_{issue.number}.txt'
            debug_file.write_text(response_text)
            print(f"   üìù Raw response saved to: {debug_file}")
            
            # Try to parse JSON with better error handling
            try:
                solution = json.loads(response_text)
            except json.JSONDecodeError as json_err:
                print(f"   ‚ö†Ô∏è  JSON parse error at line {json_err.lineno}, col {json_err.colno}")
                print(f"   üîç First 300 chars: {response_text[:300]}")
                print(f"   üîç Last 300 chars: {response_text[-300:]}")
                return {'status': 'error', 'error': f'JSON parse failed: {json_err}'}
            
            solution['status'] = 'success'
            
            print(f"   ‚úÖ Solution generated: {len(solution.get('changes', []))} file changes")
            return solution
            
        except Exception as e:
            print(f"   ‚ùå Solution generation failed: {e}")
            return {'status': 'error', 'error': str(e)}
    
    def _get_file_context(self, repo_path: Path, project: str, issue) -> str:
        """Get relevant file context for the issue"""
        context_parts = []
        
        # Parse issue for file hints
        issue_text = f"{issue.title} {issue.body or ''}"
        
        # Common patterns to look for
        if project == 'whatsapp':
            key_dirs = ['src/components', 'src/lib', 'src/types']
            key_files = ['package.json', 'tsconfig.json']
        else:
            key_dirs = ['backend', 'frontend/src']
            key_files = ['requirements.txt', 'package.json']
        
        # Get package.json or requirements.txt for dependency context
        for key_file in key_files:
            file_path = repo_path / key_file
            if file_path.exists():
                content = file_path.read_text()[:1000]
                context_parts.append(f"=== {key_file} ===\n{content}")
        
        # Get directory structure
        for key_dir in key_dirs:
            dir_path = repo_path / key_dir
            if dir_path.exists():
                files = list(dir_path.rglob('*'))[:20]
                file_list = "\n".join([str(f.relative_to(repo_path)) for f in files if f.is_file()])
                context_parts.append(f"=== {key_dir} structure ===\n{file_list}")
        
        return "\n\n".join(context_parts)
    
    def _apply_changes(self, repo_path: Path, changes: List[Dict]) -> bool:
        """Apply generated changes to the workspace"""
        print(f"üìù Applying {len(changes)} changes...")
        
        try:
            for change in changes:
                file_path = repo_path / change['file']
                action = change['action']
                
                if action == 'create':
                    file_path.parent.mkdir(parents=True, exist_ok=True)
                    file_path.write_text(change['content'])
                    print(f"   ‚úÖ Created: {change['file']}")
                    
                elif action == 'modify':
                    if file_path.exists():
                        # For now, replace entire file
                        # TODO: Implement proper diff application
                        file_path.write_text(change['content'])
                        print(f"   ‚úÖ Modified: {change['file']}")
                    else:
                        print(f"   ‚ö†Ô∏è  File not found for modify: {change['file']}")
                        
                elif action == 'delete':
                    if file_path.exists():
                        file_path.unlink()
                        print(f"   ‚úÖ Deleted: {change['file']}")
            
            return True
            
        except Exception as e:
            print(f"   ‚ùå Failed to apply changes: {e}")
            return False
    
    def _run_tests(self, repo_path: Path, project: str) -> Dict:
        """Run project tests"""
        print(f"üß™ Running tests...")
        
        try:
            if project == 'whatsapp':
                # React/TypeScript project
                result = subprocess.run(
                    ['npm', 'test', '--', '--run', '--passWithNoTests'],
                    cwd=repo_path,
                    capture_output=True,
                    text=True,
                    timeout=180
                )
            else:
                # Python/Flask project
                result = subprocess.run(
                    ['python', '-m', 'pytest', '-x', '--tb=short'],
                    cwd=repo_path,
                    capture_output=True,
                    text=True,
                    timeout=180
                )
            
            passed = result.returncode == 0
            output = result.stdout + result.stderr
            
            if passed:
                print(f"   ‚úÖ Tests passed")
            else:
                print(f"   ‚ùå Tests failed")
            
            return {'passed': passed, 'output': output}
            
        except subprocess.TimeoutExpired:
            print(f"   ‚ö†Ô∏è  Tests timed out")
            return {'passed': False, 'output': 'Tests timed out'}
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Test error: {e}")
            return {'passed': True, 'output': f'Test error (assuming pass): {e}'}
    
    def _format_code(self, repo_path: Path, project: str):
        """Format code using project formatters"""
        print(f"‚ú® Formatting code...")
        
        try:
            if project == 'whatsapp':
                subprocess.run(
                    ['npm', 'run', 'format'],
                    cwd=repo_path,
                    capture_output=True,
                    timeout=60
                )
            else:
                subprocess.run(
                    ['black', '.'],
                    cwd=repo_path,
                    capture_output=True,
                    timeout=60
                )
                subprocess.run(
                    ['isort', '.'],
                    cwd=repo_path,
                    capture_output=True,
                    timeout=60
                )
            print(f"   ‚úÖ Code formatted")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Formatting skipped: {e}")
    
    def _commit_and_push(self, repo_path: Path, branch: str, issue):
        """Commit changes and push to remote"""
        print(f"üì§ Committing and pushing...")
        
        # Create and checkout branch
        subprocess.run(['git', 'checkout', '-b', branch], cwd=repo_path, check=True)
        
        # Stage all changes
        subprocess.run(['git', 'add', '-A'], cwd=repo_path, check=True)
        
        # Commit
        commit_msg = f"feat: resolve #{issue.number} - {issue.title}\n\nü§ñ Autonomous development at 3 AM"
        subprocess.run(
            ['git', 'commit', '-m', commit_msg],
            cwd=repo_path,
            check=True
        )
        
        # Push
        subprocess.run(
            ['git', 'push', '-u', 'origin', branch],
            cwd=repo_path,
            check=True
        )
        
        print(f"   ‚úÖ Pushed to {branch}")
    
    def _create_pull_request(self, repo, branch: str, issue, solution: Dict):
        """Create pull request"""
        print(f"üîÄ Creating pull request...")
        
        pr_body = f"""## ü§ñ Autonomous Development

This PR was created by the Autonomous Developer at 3 AM.

### Issue
Resolves #{issue.number}: {issue.title}

### Analysis
{solution.get('analysis', 'No analysis provided')}

### Changes
"""
        for change in solution.get('changes', []):
            pr_body += f"- **{change['action']}** `{change['file']}`: {change.get('description', '')}\n"
        
        pr_body += f"""

### Testing
- [ ] Automated tests passed
- [ ] Manual review required

---
*Generated by Autonomous Developer v2.2 (Backlog-Driven)*
"""
        
        pr = repo.create_pull(
            title=f"ü§ñ [Autonomous] {issue.title}",
            body=pr_body,
            head=branch,
            base='main'
        )
        
        print(f"   ‚úÖ PR #{pr.number} created")
        return pr
    
    def _update_project_docs(self, repo_path: Path, issue, pr, project: str):
        """Update session log, backlog, etc."""
        print(f"üìù Updating project docs...")
        
        # WhatsApp Analyser: Update .specstory session marker
        if project == 'whatsapp':
            specstory = repo_path / '.specstory' / 'sessions'
            if specstory.exists():
                marker_file = specstory / f"autonomous_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                marker_file.write_text(f"# Autonomous Session\nIssue: #{issue.number}\nPR: {pr.html_url}\n")
        
        # HealthOS: Update SESSION_LOG.md
        else:
            session_log = repo_path / "SESSION_LOG.md"
            if session_log.exists():
                entry = f"\n## {datetime.now().strftime('%Y-%m-%d %H:%M')} - Autonomous\n**Issue**: #{issue.number}\n**PR**: {pr.html_url}\n\n---\n"
                existing = session_log.read_text()
                session_log.write_text(entry + existing)
                
                # Commit the log update
                subprocess.run(['git', 'add', 'SESSION_LOG.md'], cwd=repo_path)
                subprocess.run(['git', 'commit', '-m', 'docs: update SESSION_LOG'], cwd=repo_path)
                subprocess.run(['git', 'push'], cwd=repo_path)
